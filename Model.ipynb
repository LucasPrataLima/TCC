{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0cf81bb-d41b-455c-bfd3-3fa3a529d931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Dropout, Input\n",
    "import keras\n",
    "from keras.callbacks import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8bf3b73-dc2d-491b-b1ce-f1be11d92312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando dados\n",
    "data = pd.read_excel(r'Conjunto de Dados Completo Original.xlsx')\n",
    "data = data[['Chuva_observada (mm)', 'Chuva_Acum (mm)', 'ENA_Grande (MWmed)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c09612a-c246-4e4a-8639-9a50215bba2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Definindo parâmetros\n",
    "sequence_length = 12\n",
    "batch_size = 32\n",
    "stride = 1\n",
    "learning_rate = 0.001\n",
    "train_cut = int(0.7*len(data))\n",
    "\n",
    "\n",
    "# Escalonando todos os dados para o intervalo entre 0 e 1\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data[:train_cut])\n",
    "data_scaled = scaler.transform(data)\n",
    "\n",
    "scaler_Y = MinMaxScaler()\n",
    "scaler_Y.fit(data[['ENA_Grande (MWmed)']][:train_cut])\n",
    "\n",
    "# Convertendo o array numpy de volta para um DataFrame\n",
    "data_scaled_df = pd.DataFrame(data_scaled, columns=data.columns)\n",
    "\n",
    "# Separando inputs e targets\n",
    "inputs = data_scaled_df[['Chuva_Acum (mm)', 'ENA_Grande (MWmed)']]\n",
    "inputs = inputs.iloc[:-sequence_length]\n",
    "targets = data_scaled_df.loc[sequence_length:, 'ENA_Grande (MWmed)']\n",
    "\n",
    "\n",
    "# Criando o dataset\n",
    "full_dataset = timeseries_dataset_from_array(\n",
    "    inputs,\n",
    "    targets,\n",
    "    sequence_length=sequence_length,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Converte o dataset em listas de arrays para divisão\n",
    "inputs_list = []\n",
    "targets_list = []\n",
    "\n",
    "for batch in full_dataset:\n",
    "    inputs, targets = batch\n",
    "    inputs_list.extend(inputs.numpy())\n",
    "    targets_list.extend(targets.numpy())\n",
    "\n",
    "# Converte listas para arrays\n",
    "inputs_array = np.array(inputs_list)\n",
    "targets_array = np.array(targets_list)\n",
    "\n",
    "# Divide os dados em treinamento, validação e teste (70%, 20%, 10%)\n",
    "train_size = int(0.7 * len(inputs_array))\n",
    "val_size = int(0.2 * len(inputs_array))\n",
    "test_size = len(inputs_array) - train_size - val_size\n",
    "\n",
    "x_train = inputs_array[:train_size]\n",
    "y_train = targets_array[:train_size]\n",
    "\n",
    "x_val = inputs_array[train_size:train_size + val_size]\n",
    "y_val = targets_array[train_size:train_size + val_size]\n",
    "\n",
    "x_test = inputs_array[train_size + val_size:]\n",
    "y_test = targets_array[train_size + val_size:]\n",
    "\n",
    "# Cria datasets de treinamento, validação e teste\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22b6c520-698c-4f8d-9803-f822634d2c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (32, 12, 2)\n",
      "Target shape: (32,)\n"
     ]
    }
   ],
   "source": [
    "# Verificando os formatos de inputs e targets\n",
    "for batch in train_dataset.take(1):\n",
    "    inputs, targets = batch\n",
    "\n",
    "print(\"Input shape:\", inputs.numpy().shape)\n",
    "print(\"Target shape:\", targets.numpy().shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec20a954-da1b-4fa9-b77d-ef6b94b3d615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a arquitetura do modelo\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(inputs.shape[1], inputs.shape[2])))\n",
    "model.add(LSTM(units=12, return_sequences=True))\n",
    "model.add(LSTM(units=12))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef33305a-cbc1-40f3-a45e-87c59ac2b868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m)         │           \u001b[38;5;34m720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │         \u001b[38;5;34m1,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m13\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,933</span> (7.55 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,933\u001b[0m (7.55 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,933</span> (7.55 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,933\u001b[0m (7.55 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59c973d-6ef0-4130-98d2-32d9d4734731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 3s/step - loss: 0.0614"
     ]
    }
   ],
   "source": [
    "# Definindo callbacks\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', verbose=0, patience=30)\n",
    "mcp_save = ModelCheckpoint('trained_models/LSTM.keras', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# Treinando o modelo\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=2000,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[earlyStopping, mcp_save],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dc0665-0003-47b5-a25f-1f95116f0c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico das curvas de custo do treinamento e validação\n",
    "def visualize_loss(history, title):\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(len(loss))\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_loss(history, \"Training and Validation Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d76ed63-3ed5-4473-8e29-5fa52185c80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega melhor modelo\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('trained_models/LSTM.keras',compile=False)\n",
    "\n",
    "# Faz previsões\n",
    "train_predict = model.predict(x_train)\n",
    "val_predict = model.predict(x_val)\n",
    "test_predict = model.predict(x_test)\n",
    "\n",
    "# inverso das previsões\n",
    "train_predict_inv = scaler_Y.inverse_transform(train_predict.reshape(-1, 1))\n",
    "val_predict_inv = scaler_Y.inverse_transform(val_predict.reshape(-1, 1))\n",
    "test_predict_inv = scaler_Y.inverse_transform(test_predict.reshape(-1, 1))\n",
    "\n",
    "# Inverso dos valores reais\n",
    "train_real_inv = scaler_Y.inverse_transform(y_train.reshape(-1, 1))\n",
    "val_real_inv = scaler_Y.inverse_transform(y_val.reshape(-1, 1))\n",
    "test_real_inv = scaler_Y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Plota os resultados\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(train_real_inv.flatten(), label='Real Train')\n",
    "plt.plot(train_predict_inv.flatten(), label='Predicted Train')\n",
    "plt.plot(np.arange(len(y_train), len(y_train) + len(y_val)), val_real_inv.flatten(), label='Real Val')\n",
    "plt.plot(np.arange(len(y_train), len(y_train) + len(y_val)), val_predict_inv.flatten(), label='Predicted Val')\n",
    "plt.plot(np.arange(len(y_train) + len(y_val), len(y_train) + len(y_val) + len(y_test)), test_real_inv.flatten(), label='Real Test')\n",
    "plt.plot(np.arange(len(y_train) + len(y_val), len(y_train) + len(y_val) + len(y_test)), test_predict_inv.flatten(), label='Predicted Test')\n",
    "plt.legend()\n",
    "plt.ylabel('ENA_Grande (MWmed)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a43653-25d6-47b9-9366-bab1e62ae254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular as métricas\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    correlation, _ = pearsonr(y_true, y_pred)\n",
    "    return mae, rmse, mape, r2, correlation\n",
    "\n",
    "# Calcula métricas para o conjunto de treinamento\n",
    "train_mae, train_rmse, train_mape, train_r2, train_correlation = calculate_metrics(train_real_inv[1:].flatten(), train_predict_inv[1:].flatten())\n",
    "\n",
    "# Calcula métricas para o conjunto de validação\n",
    "val_mae, val_rmse, val_mape, val_r2, val_correlation = calculate_metrics(val_real_inv[1:].flatten(), val_predict_inv[1:].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64d04ec-0af8-47c5-86ac-5231559a9425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime os resultados\n",
    "print(\"Modelo LSTM:\")\n",
    "print(f\"Conjunto de treinamento: MAE = {train_mae}, RMSE = {train_rmse}, MAPE = {train_mape}, R^2 = {train_r2}, Correlation = {train_correlation}\")\n",
    "print(f\"Conjunto de validação: MAE = {val_mae}, RMSE = {val_rmse}, MAPE = {val_mape}, R^2 = {val_r2}, Correlation = {val_correlation}\")\n",
    "#print(f\"Conjunto de teste: MAE = {test_mae}, RMSE = {test_rmse}, MAPE = {test_mape}, R^2 = {test_r2}, Correlation = {test_correlation}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
